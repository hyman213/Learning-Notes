# 通过下订单理解微服务架构

## 问题描述

> 问题：用户再电商网站中购买成功了，它在微服务中经历了什么

**模块**

- 用户
- 商品(库存)
- 订单
- 支付

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720094349)

**流程图**

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720094419)

### 服务拆分

**DDD(领域驱动设计)**

Domain-driven Design

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720095735)

总体架构分为四层：

- Infrastructure（基础实施层）
- Domain（领域层）
- Application（应用层）
- Interfaces（表示层，也叫用户界面层或是接口层）
- 微服务结合 DDD

**实施DDD的关键**

第一点是使用通过的语言建立所有的聚合，实体，值对象。

第二点也就是最关键的“建模”：

- 划分“战略建模”，从一种宏观的角度去审核整个项目，划分出“界限上下文”，形成具有上帝视角的“上下文映射图”。
- 还有一个建模是“战术建模”，在我们的“战略建模”划分出来的“界限上下文”中进行“聚合”，“实体”，“值对象”，并按照模块分组。

**构建电商系统的上下文映射图**

作为一个电商系统，我们的核心肯定是卖出更多的商品，获取更多订单更多的利润，那么销售可以作为我们的一个核心的领域。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100122)

根据对这个领域的理解划分出各个上下文，然后根据上下文再确定其他的相关领域。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100148)

初步我们可以看出围绕销售核心域的包含的几大块内容，价格，销售方式，购买的方式，已经购买。

然后我们对支撑着核心域的子域也做了划分，支撑着核心域的有商品域，用户域，通用域有订单域，物流域，支付域。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100242)

我们将微服务拆分为 5 个领域，分别是：

- 销售域
- 商品域
- 用户域
- 订单域
- 支付域

### 时序图

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100335)

### 微服务技术栈选型

- Dubbo - 阿里
- Spring Cloud
- Motan - 新浪

Dubbo 和 Spring Cloud 比喻，Dubbo 架构的微服务就像组装电脑，各个环节自由度很高。Spring Cloud 更像品牌机。

**微服务利弊**

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100602)

**逻辑分层**

如果客户端向查看 “我的订单” 这么一个接口；如果客户端假定是 PC 端，就需要请求三次接口，分别对接订单，商品，用户三个服务，分别拿完三次调用数据，再将三次调用数据进行整合输出展示。

要知道 PC 调用后端服务是走外网，这无疑大大增加了网络的开销，而且让 PC 端变成更为复杂。

假定在中间加多一个层为聚合服务层，即对网络开销进行减少，因为微服务内部是通过内网进行数据传输，也让 PC 端的业务变得比较简单。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100723)



图中的 “PC 聚合服务” 也是一个微服务，只不过它是属于聚合服务中间层，我们将为微服务进行逻辑划分，分为 2 个层：

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100816)

**微服务基础服务层**

基础服务一般属于互联网平台基础性的支撑服务，比方说，电商网站的基础服务有订单服务，商品服务，用户服务等。

**微服务聚合服务层**

已经有了基础服务能提供业务能力，为什么还需要聚合服务，因为我们有不同的接入端，如 App 和 H5，PC 等等，它们看似调用大致相同的数据，但其实存在很多差异。

例如 PC 需要展示更多信息，App 需要做信息裁剪等等。一般低层服务都是比较通用的，基础服务应该对外输出相对统一的服务，在抽象上做得比较好。

但是对不同的外界 App 和 PC 的接入，我们需要作出不同的适配，这个时候需要有一个层去做出聚合裁剪的工作。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720100933)

## 分布式事务

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101019)

技术方案：

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101052)

先排除掉我们应该不会选择的方案，一个是 XA 两阶段提交，这个在很多传统型公司会被使用，但不适合互联网微服务的分布式系统，锁定资源时间长，性能影响大，排除。

另一个是阿里的 GTS，并没有开源，目前已经开源了 Fescar，不过目前尚缺少调研，可能在下个阶段研究后会使用，目前先排除。

剩下的是 TCC 和 MQ 消息事务两种。

**MQ 消息事务：RocketMQ**

先说说 MQ 的分布式事务，RocketMQ 在 4.3 版本已经正式宣布支持分布式事务，在选择 RokcetMQ 做分布式事务请务必选择 4.3 以上的版本。

事务消息作为一种异步确保型事务， 将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示：

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101151)

**TCC 方案**

TCC 是服务化的二阶段变成模型，每个业务服务都必须实现 Try，Confirm，Calcel 三个方法。

这三个方式可以对应到 SQL 事务中 Lock，Commit，Rollback：

- Try 阶段：Try 只是一个初步的操作，进行初步的确认，它的主要职责是完成所有业务的检查，预留业务资源。
- Confirm 阶段：Confirm 是在 Try 阶段检查执行完毕后，继续执行的确认操作，必须满足幂等性操作，如果 Confirm 中执行失败，会有事务协调器触发不断的执行，直到满足为止。
- Cancel：是取消执行，在 Try 没通过并释放掉 Try 阶段预留的资源，也必须满足幂等性，跟 Confirm 一样有可能被不断执行。

接下来看看，我们的下单扣减库存的流程怎么加入 TCC：

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101340)

在 Try 的时候，会让库存服务预留 n 个库存给这个订单使用，让订单服务产生一个“未确认”订单，同时产生这两个预留的资源。

在 Confirm 的时候，会使用在 Try 预留的资源，在 TCC 事务机制中认为，如果在 Try 阶段能正常预留的资源，那么在 Confirm 一定能完整的提交：

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101411)

在 Try 的时候，有任务一方为执行失败，则会执行 Cancel 的接口操作，将在 Try 阶段预留的资源进行释放。

有同学可能会问了，如果在 Confirm 或 Cancel 中，有一方的操作失败了，可能出现异常等情况该怎么解决。

- 这个就涉及 TCC 的事务协调器了，事务协调器就 Confirm 或 Cancel 没有得到返回的时候，会启用定时器不断的进行 Confirm 或 Cancel 的重试。

  这个也就是我们强调，Confirm，Cancel 接口必须是幂等性的一个原因了。

- 还有同学会问了，为什么事务协调器知道 Confirm，或 Cancel 没有完成。

  这个就涉及到了 TCC 也做了一张本地消息表，会记录一次事务，包括主事务，子事务，事务的完成情况都会记录在这种表中（当然未必是表，可能是 ZK，Redis 等等介质），然后启用一个定时器去检查这种表。

- 还有同学会问，事务怎么传递，这个就涉及使用的 TCC 的框架了，一般来说用的都是隐式传参的方式。

  在主事务创建的时候用隐式传参调用子事务，子事务包含 Try，Confirm，Cancel 都会记录到事务表里面。

这里推荐 TCC 的开源框架使用 mengyun 的 TCC

## 熔断限流隔离降级

下面使用 Hystrix 例子来讲解一下限流熔断。

几个概念：熔断，隔离，限流，降级，这几个概念是分布式容错最重要的概念和模式。

①熔断：如果说房子里面安装了电路熔断器，当你使用超大功率的电路时，有熔断设备帮你保护不至于出问题的时候把问题扩大化。

②隔离：我们知道计算资源都是有限的，CPU，内存，队列，线程池都是资源。

他们都是限定的资源数，如果不进行隔离，一个服务的调用可能要消耗很多的线程资源，把其他服务的资源都给占用了，那么可能出现因为一个服务的问题连带效应造成其他服务不能进行访问。

③限流：让大流量的访问冲进去我们的服务时，我们需要一定的限流措施，比方说我们规则一定时间内只允许一定的访问数从我们的资源过，如果再大的话系统会出现问题，那么就需要限流保护。

④降级：如果说系统后台无法提供足够的支撑能力，那么需要一个降级能力，保护系统不会被进一步恶化，而且可以对用户提供比较友好的柔性方案，例如告知用户暂时无法访问，请在一段时候后重试等等。

**Hystrix**

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101601)

大致的工作流如下：

- 构建一个 HystrixCommand 对象，用于封装请求，并在构造方法配置请求被执行需要的参数。
- 执行命令，Hystrix 提供了几种执行命令的方法，比较常用到的是 Synchrous 和 Asynchrous。
- 判断电路是否被打开，如果被打开，直接进入 Fallback 方法。
- 判断线程池/队列/信号量是否已经满，如果满了，直接进入 Fallback 方法。
- 执行 Run 方法，一般是 HystrixCommand.run()，进入实际的业务调用，执行超时或者执行失败抛出未提前预计的异常时，直接进入 Fallback 方法。
- 无论中间走到哪一步都会进行上报 Metrics，统计出熔断器的监控指标。
- Fallback 方法也分实现和备用的环节。
- 最后是返回请求响应。

## 集中式配置中心

- Spring Cloud Config
- Disconf - 百度
- Diamond - 阿里
- Apollo - 携程

基本上他们的原理都差不多，配置中心可以简单的理解为一个服务模块，开发人员或运维人员可以通过界面对配置中心进行配置。

下面相关的微服务连接到配置中心上面就可以实时连接获取到配置中心上面修改的参数。

更新的方式一般有两种：

- Pull 模式，服务定时去拉取配置中心的数据。
- Push 模式，服务一直连接到配置中心上，一旦配置有变成，配置中心将把变更的参数推送到对应的微服务上。

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101758)

Pull 和 Push 两种模式各有优缺点：

- Pull 一般使用定时器拉取，就算某一个网络抖动没有 Pull 成功，在下一次定时器的时候，终将能保证获取最新的配置。
- Push 可以避免 Pull 定时器存在的延时，基本可以做到实时获取数据，但也有问题就是网络抖动的时候可能会丢失更新。

**携程的 Apollo**

![](https://raw.githubusercontent.com/hyman213/FigureBed/master/2019/07/20190720101830)

开发或运维人员在配置中心进行修改，配置中心服务将实时将修改推送 Push 到 Apollo 的客户端。

但考虑到可能由于某些网络抖动没有推送成功，客户端还具备了定时向 Apollo 服务端拉取 Pull 数据的功能。

就算推送没成，但是只要一定时间周期，客户端还是会主动去拉取同步数据，保证能把最终配置同步到服务中。这个也是 Apollo 在高可用方面上非常有特色的设计。

Apollp 在高可用上也做了保证，客户端获取到数据会把数据缓存在内存，还会 Sync 到本地磁盘。

就算 Apollo 服务器挂掉了，就算客户端服务重启了，也可以从本地磁盘中拉取回来数据，继续提供对外服务，从这点来看 Apollo 的配置中心在高可用上考虑还是比较周到的。

## 调用链监控&日志

- 鹰眼 - 阿里
- CAT - 点评

目前市面主流的调用链选型有 Zipkin，Pinpoint，Cat，Skywalking

## Docker + Kubernetes



## 预估容量

**评估访问量**

①问运营，如果是一个已经上线的产品，肯定存在已有的用户数和访问数据，就算存在偏差，也是可控的范围。

②问产品，确定一个什么样形态的产品，例如是拼团，例如是秒杀，各种处理方式都不同。

**评估平均访问量 QPS**

一天 86400 秒，一般认为请求大部分发生在白天，就按照 40000 计算，日平均访问量=日总访问量/40000。

**评估高峰 QPS**

可以把之前每日的访问曲线图拉出来看看，峰值是根据业务不同而定的，例如，有些业务是白天早上 10 点的流量偏多，有些业务是晚上人家休闲类的流量偏多。

总之，根据业务去估算出日均的峰值，类似于电商类的服务，一般峰值是日均流量的 5 倍左右。

还有例如一些大促活动可能会更高，这个都要跟运营人员提前沟通好的，还有一些活动例如，秒杀，这个就不是靠预估出来，秒杀是另一种的考虑情况，采取的应对策略跟普通订单是完全不同。

**评估系统，单机极限 QPS**

在上线之前需要跟测试人员一起做压力测试，针对每个服务每台机器去做，一般来说，会把一个服务一台机器压到极限，在逐步的进行优化。

假定单台机器最大的 QPS 是 1000，我们峰值是 5000，那需要用多少台机器去抗？答案是大于等于 6 台，最少的容错不得少于 1 台。

## 参考文章

[通过下订单理解微服务架构](https://mp.weixin.qq.com/s/5oMaieilGC69L5mjQtFCfQ)